{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preditor de Vencedores de Partidas da Premier League\n",
        "\n",
        "**Aluno:** Luiz Fernando Rabelo (11796893)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O presente notebook faz parte da resolução do Projeto Final da disciplina de Introdução à Ciência de Dados (SME0828). Nele, são analisados dados estatísticos de partidas de futebol do campeonato inglês (Premier League), com o objetivo de construir modelos de aprendizado de máquina que tentam prever qual dos times saiu vencedor, ou se ocorreu um empate em dada partida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descrição do Dataset\n",
        "\n",
        "Podemos começar a análise descrevendo o conjunto de dados. Foram baixadas estatísticas de partidas de 18 temporadas da Premier League (de 2005 a 2022) da plataforma https://www.football-data.co.uk/. As estatísticas baixadas foram armazenados na pasta \"data\", no formato CSV. Os atributos estatísticos podem ser divididos entre Estatísticas da Partida, Estatísticas de Resultados e Estatísticas de Casas de Apostas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Estatísticas da Partida:**\n",
        "\n",
        "- **Div:** sigla da liga da partida (neste caso sempre \"E0\")\n",
        "- **Date:** data de realização da partida\n",
        "- **HomeTeam:** nome do time mandante\n",
        "- **AwayTeam:** nome do time visitante\n",
        "- **Referee:** nome do árbitro\n",
        "- **HS:** número de chutes ao gol (totais) do time mandante\n",
        "- **AS:** número de chutes ao gol (totais) do time visitante\n",
        "- **HST:** número de chutes ao gol (certos) do time mandante\n",
        "- **AST:** número de chutes ao gol (certos) do time visitante\n",
        "- **HC:** número de escanteios do time mandante\n",
        "- **AC:** número de escanteios do time visitante\n",
        "- **HF:** número de faltas cometidas pelo time mandante\n",
        "- **AF:** número de faltas cometidas pelo time visitante\n",
        "- **HY:** número de cartões amarelos do time mandante\n",
        "- **AY:** número de cartões amarelos do time visitante\n",
        "- **HR:** número de cartões vermelhos do time mandante\n",
        "- **AR:** número de cartões vermelhos do time visitante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Estatísticas de Resultados:**\n",
        "\n",
        "- **FTHG:** número gols do time mandante ao final da partida \n",
        "- **FTAG:** número gols do time visitante ao final da partida \n",
        "- **FTR:** sigla do vencedor da partida (H=mandante, A=time visitante, D=empate) \n",
        "- **HTR:** vencedor parcial da partida ao intervalo (H=mandante, A=time visitante, D=empate) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Estatísticas de Casas de Apostas:** (\\*)\n",
        "\n",
        "- **AvgH**: média das odds para vitória do time mandante \n",
        "- **AvgD**: média das odds para empate\n",
        "- **AvgA**: média das odds para vitória do time visitante\n",
        "\n",
        "(\\*) O dataset possui diversos outros atributos relacionados à odds de eventos em plataformas de apostas. Mas foram utilizados apenas os atributos supracitados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importação de Bibliotecas\n",
        "\n",
        "Para o trabalho, foram utilizadas as bibliotecas _pandas_ para manipulação de DataFrames, _numpy_ para o processamento de dados, _seaborn_ e _matplotlib_ para construção de gráficos e _sklearn_ para a preparação, análise de dados e construção de modelos de aprendizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Leitura dos Dados\n",
        "\n",
        "Começamos definindo o intervalo de temporadas de interesse. Cada temporada se inicia no começo do 2° semestre de um ano e termina no fim do 1° semestre do ano seguinte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ANO_INICIAL = 2005\n",
        "ANO_FINAL = 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Em seguida, guardamos os dados de todas as temporadas no dataframe `dados_pl`, armazenando também as informações lidas segmentadas por temporada no dicionário `dados_pl_por_temporada`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_pl = None\n",
        "dados_pl_por_temporada = {}\n",
        "\n",
        "for ano in range(ANO_INICIAL, ANO_FINAL):\n",
        "    temporada_atual = f'{ano}-{ano+1}'\n",
        "    dados_pl_por_temporada[temporada_atual] = pd.read_csv(f'./data/english-pl-{temporada_atual}.csv', encoding='unicode_escape')\n",
        "    if dados_pl is None:\n",
        "        dados_pl = dados_pl_por_temporada[temporada_atual]\n",
        "    else:\n",
        "        dados_pl = pd.concat([dados_pl, dados_pl_por_temporada[temporada_atual]], ignore_index=True)\n",
        "\n",
        "print('Shape do dataset original lido:', dados_pl.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análises Iniciais\n",
        "\n",
        "### Distribuição dos Resultados Históricos\n",
        "\n",
        "Vamos, inicialmente, visualizar a distribuição dos possíveis resultados (H = time mandante vencedor; D = empate; A = time visitante vencedor) das partidas ao longo da história."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "contagens_resultados = dados_pl['FTR'].value_counts()\n",
        "\n",
        "percentuais_resultados = [\n",
        "    100 * contagens_resultados[r] / sum(contagens_resultados.values) for r in contagens_resultados.keys()\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(contagens_resultados.keys(), contagens_resultados.values, color='darkcyan', ec='black')\n",
        "\n",
        "for i in range(len(percentuais_resultados)):\n",
        "    plt.text(i, contagens_resultados[i] + 1, f'{percentuais_resultados[i]:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.title('Resultados dos Jogos ao Longo da História', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.xlabel('Resultado da Partida', fontsize=12)\n",
        "plt.ylabel('Número de ocorrências', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No futebol, o chamado \"Fator Casa\" é bastante conhecido. Em resumo, esse fator sugere que o time mandante de uma partida, geralmente possui certas vantagens sobre o time visitante, podendo ser citadas:\n",
        "\n",
        "- maior conhecimento do gramado da partida (embora as diferenças no tipo da grama e nas dimensões dos gramados de partidas oficiais sejam pequenas);\n",
        "- recepção da maior parcela da torcida presente no estádio (a qual ajuda a motivar o time mandante e a pressionar o visitante);\n",
        "- menor deslocamento para o estádio no período que antecede o jogo (dependendo do jogo, o time visitante deve viajar por quilômetros até o local da partida, e esse deslocamento pode gerar um pequeno desgaste físico para os jogadores).\n",
        "\n",
        "O Fator Casa, de fato, parece influenciar os resultados das partidas, uma vez que, em quase metade das partidas do conjunto de dados, o time mandante saiu vencedor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fator Casa por Temporada\n",
        "\n",
        "Se prosseguirmos com a análise do Fator Casa, agora analisando a pontuação dos times por temporada, chegaremos em um fato interessante: o fator casa não foi tão determinante, ao menos não como nos outros anos, nos resultados das partidas ocorridas durante a pandemia causada pela COVID-19."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pontuacoes_mandantes = []\n",
        "temporadas = []\n",
        "cores = []\n",
        "\n",
        "for ano in range(ANO_INICIAL, ANO_FINAL):\n",
        "    temporada_atual = f'{ano}-{ano+1}'\n",
        "    pontos_vitorias_m = dados_pl_por_temporada[temporada_atual]['FTR'].value_counts()['H'] * 3\n",
        "    pontos_empates = dados_pl_por_temporada[temporada_atual]['FTR'].value_counts()['D'] * 1\n",
        "    pontuacoes_mandantes.append(pontos_vitorias_m + pontos_empates)\n",
        "    temporadas.append(temporada_atual)\n",
        "    cores.append('darkred' if ano == 2020 else 'forestgreen')\n",
        "\n",
        "media_pontos_mandantes = sum(pontuacoes_mandantes) / len(pontuacoes_mandantes)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(temporadas, pontuacoes_mandantes, color=cores, ec='black')\n",
        "plt.xticks(rotation=75)\n",
        "plt.title('Pontuações dos Times Como Mandantes por Temporada', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.xlabel('Temporada', fontsize=12)\n",
        "plt.ylabel('Pontuação', fontsize=12)\n",
        "plt.axhline(y=media_pontos_mandantes, c='darkorange', ls='--', label='Média Histórica')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pontuacoes_visitantes = []\n",
        "temporadas = []\n",
        "cores = []\n",
        "\n",
        "for ano in range(ANO_INICIAL, ANO_FINAL):\n",
        "    temporada_atual = f'{ano}-{ano+1}'\n",
        "    pontos_vitorias_v = dados_pl_por_temporada[temporada_atual]['FTR'].value_counts()['A'] * 3\n",
        "    pontos_empates = dados_pl_por_temporada[temporada_atual]['FTR'].value_counts()['D'] * 1\n",
        "    pontuacoes_visitantes.append(pontos_vitorias_v + pontos_empates)\n",
        "    temporadas.append(temporada_atual)\n",
        "    cores.append('darkred' if ano == 2020 else 'forestgreen')\n",
        "\n",
        "media_pontos_visitantes = sum(pontuacoes_visitantes) / len(pontuacoes_visitantes)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(temporadas, pontuacoes_visitantes, color=cores, ec='black')\n",
        "plt.xticks(rotation=75)\n",
        "plt.title('Pontuações dos Times Como Visitantes por Temporada', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.xlabel('Temporada', fontsize=12)\n",
        "plt.ylabel('Pontuação', fontsize=12)\n",
        "plt.axhline(y=media_pontos_visitantes, c='darkorange', ls='--', label='Média Histórica')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Essa \"anormalidade\" pode ser explicada pelas questões sanitárias da temporada 2020-2021, que iniciou com portões fechados para torcida e assim permaneceu pela maior parte do tempo, com exceção de um breve período em que os clubes puderam convidar um número limitado de torcedores para voltar aos estádios. O desvio nas pontuações dos times em casa fortificou a opinião de muitos especialistas em futebol de que a presença da torcida nas partidas exerce forte influência positiva para o time mandante.\n",
        "\n",
        "Os detalhes de como a COVID-19 afetou o campeonato inglês podem ser conferidos em https://www.premierleague.com/news/1682374."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Desempenho dos Maiores Clubes\n",
        "\n",
        "Outra análise interessante de ser feita é a do desempenho geral dos grandes clubes do Campeonato Inglês. Na Premier League, existem 6 clubes considerados de elite, são eles: Arsenal, Chelsea, Liverpool, Manchester United, Manchester City e Tottenham. Esse grupo de times recebeu o nome de \"Big Six\" na Inglaterra. Podemos comparar o desempenho dos clubes do Big Six com os demais.\n",
        "\n",
        "Primeiro, definimos a lista dos nomes dos clubes pertencentes ao grupo de elite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "times_big_six = ['Arsenal', 'Chelsea', 'Liverpool', 'Man United', 'Man City', 'Tottenham']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Então definimos filtros para os casos de pontuação por vitória e por empate para cada grupo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "condicao_vitoria_b6 = (\n",
        "    (dados_pl['HomeTeam'].isin(times_big_six)) & (dados_pl['FTR'] == 'H') | \n",
        "    (dados_pl['AwayTeam'].isin(times_big_six)) & (dados_pl['FTR'] == 'A')\n",
        ")\n",
        "\n",
        "condicao1_empate_b6 = (\n",
        "    (dados_pl['HomeTeam'].isin(times_big_six)) ^ (dados_pl['AwayTeam'].isin(times_big_six)) &\n",
        "    (dados_pl['FTR'] == 'D')\n",
        ")\n",
        "\n",
        "condicao2_empate_b6 = (\n",
        "    (dados_pl['HomeTeam'].isin(times_big_six)) & (dados_pl['AwayTeam'].isin(times_big_six)) &\n",
        "    (dados_pl['FTR'] == 'D')\n",
        ")\n",
        "\n",
        "condicao_vitoria_demais = (\n",
        "    (~(dados_pl['HomeTeam'].isin(times_big_six))) & (dados_pl['FTR'] == 'H') | \n",
        "    (~(dados_pl['AwayTeam'].isin(times_big_six))) & (dados_pl['FTR'] == 'A')\n",
        ")\n",
        "\n",
        "condicao1_empate_demais = (\n",
        "    (~(dados_pl['HomeTeam'].isin(times_big_six))) ^ (~(dados_pl['AwayTeam'].isin(times_big_six))) &\n",
        "    (dados_pl['FTR'] == 'D')\n",
        ")\n",
        "\n",
        "condicao2_empate_demais = (\n",
        "    (~(dados_pl['HomeTeam'].isin(times_big_six))) & (~(dados_pl['AwayTeam'].isin(times_big_six))) &\n",
        "    (dados_pl['FTR'] == 'D')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assim, aplicamos os filtros no dataset, contabilizando as quantidades de vitória e de empates para cada grupo. Vale destacar que, se 2 times do mesmo grupo se enfrentarem e houver empate, o empate deve ser contabilizado 2 vezes, pois ambos os times pontuarão nesse cenário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vitorias_b6 = dados_pl[condicao_vitoria_b6].shape[0]\n",
        "empates_b6 = dados_pl[condicao1_empate_b6].shape[0] + 2 * dados_pl[condicao2_empate_b6].shape[0]\n",
        "\n",
        "vitorias_demais = dados_pl[condicao_vitoria_demais].shape[0]\n",
        "empates_demais = dados_pl[condicao1_empate_demais].shape[0] + 2 * dados_pl[condicao2_empate_demais].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostramos, então, a divisão das pontuações por grupo (3 pontos por vitória e 1 ponto por empate) acumuladas ao longo da hisória."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pontuacoes = {\n",
        "    'Times Big 6': vitorias_b6 * 3 + empates_b6 * 1,\n",
        "    'Demais Times':  vitorias_demais * 3 + empates_demais * 1,\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(pontuacoes.values(), labels=pontuacoes.keys(), startangle=90, autopct='%1.1f%%', explode=[0, 0.05], colors=['darkcyan', 'coral'])\n",
        "plt.title('Pontuações dos Times por Grupo (Big 6 vs Demais)', fontdict={'size': 12, 'weight': 'bold'});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dos 42 times que disputaram a Premiere League durante o período, 6 foram responsáveis pelo significativo percentual de quase 40% da pontuação histórica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparação dos Dados\n",
        "\n",
        "### Seleção dos Atributos de Interesse\n",
        "\n",
        "Vamos iniciar a preparação dos dados para a contrução dos modelos. Começamos selecionando os atributos de interesse. Nessa etapa, é descartada a divisão da liga (que é sempre a mesma dentro do conjunto de dados), o nome do árbitro da partida (que, em tese, não deve influenciar no resultado) e os atributos de casas de apostas, com exceção das odds para cada evento relacionado ao resultado, calculadas no início da partida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas_interesse = [\n",
        "    'Date', 'HomeTeam', 'AwayTeam', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'AvgH', 'AvgD', 'AvgA', 'HTR', 'FTR'\n",
        "]\n",
        "\n",
        "colunas_nao_interesse = [nome_coluna for nome_coluna in dados_pl.columns if nome_coluna not in colunas_interesse]\n",
        "\n",
        "dados_pl.drop(columns=colunas_nao_interesse, inplace=True)\n",
        "print('Shape do dataset filtrado:', dados_pl.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verificação de Valores Nulos\n",
        "\n",
        "Veremos quais são as colunas mais afetadas por valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_pl.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como os dados de odds de apostas esportivas foram disponibilizados apenas a partir de 2019, a maior parte dessa coluna possui valores vazios. Isso é um problema, pois as chances de vitória ao início das partidas para cada time são difíceis de ser preenchidas por uma simples regressão, e, nesse sentido, para fins de simplificação, vamos considerar que as probabilidades para cada evento sejam de:\n",
        "\n",
        "- vitória do mandante: $p_H = \\frac{1}{2}$\n",
        "- empate: $p_D = \\frac{1}{4}$\n",
        "- vitória do visitante: $p_A = \\frac{1}{4}$\n",
        "\n",
        "Assim, podemos determinar as odds exclusivamente em função da probabilidade de cada evento, sem considerar o risco de mercado, como $odd_H\\frac{1}{\\frac{1}{2}} = 2$, $odd_D = odd_A = \\frac{1}{\\frac{1}{4}} = 4$.\n",
        "\n",
        "Preenchemos, então, as odds faltantes no conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_pl['AvgH'].fillna(2, inplace=True)\n",
        "dados_pl['AvgD'].fillna(4, inplace=True)\n",
        "dados_pl['AvgA'].fillna(4, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Os outros atributos que ainda possuem valores nulos estão associados à um único registro do dataset. Sendo assim, podemos optar por apenas removê-lo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_pl.dropna(inplace=True)\n",
        "dados_pl.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ao todo, 5321 registros tiveram as colunas de odds alteradas e 1 registro foi excluído."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversão da Data\n",
        "\n",
        "A data de realização da partida, em si, pode não parecer tão relevante para influenciar em seu resultado. Entretanto, como mostrado na análise inicial, o Fator Casa teve um impacto diferente durante a pandemia. Podemos então, em vez de utilizar a data específica da partida, categoriza-la como pandêmica ou normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "is_data_pandemica = lambda data: \\\n",
        "    int(data.split('/')[2]) == 2020 and int(data.split('/')[1]) >= 9 or \\\n",
        "    int(data.split('/')[2]) == 2021 and int(data.split('/')[1]) <= 5\n",
        "\n",
        "dados_pl['Date'] = dados_pl['Date'].apply(\n",
        "    lambda data: 'pandemic' if is_data_pandemica(data) else 'regular'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pelo período de análise, a maioria das datas foram regulares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "value_counts_date = dados_pl['Date'].value_counts()\n",
        "\n",
        "qtd_datas_pandemicas_total = value_counts_date['pandemic']\n",
        "qtd_datas_nao_pandemicas_total = value_counts_date['regular']\n",
        "\n",
        "print(qtd_datas_pandemicas_total, 'datas pandêmicas')\n",
        "print(qtd_datas_nao_pandemicas_total, 'datas não pandêmicas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separação dos Times em Grupos\n",
        "\n",
        "Como mostrado, também na análise inicial, os times principais do campeonato são responsáveis por um percentual significativo das pontuações históricas. Assim, é possível dividir os times entre pertencentes ao Big Six ou aos outros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_pl['HomeGroup'] = dados_pl['HomeTeam'].apply(\n",
        "    lambda team: 'Big6' if team in times_big_six else 'Others'\n",
        ")\n",
        "\n",
        "dados_pl['AwayGroup'] = dados_pl['AwayTeam'].apply(\n",
        "    lambda team: 'Big6' if team in times_big_six else 'Others'\n",
        ")\n",
        "\n",
        "dados_pl.drop(columns=['HomeTeam', 'AwayTeam'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversão do Resultado da Partida\n",
        "\n",
        "Os possíveis resultados das partidas (H = time mandante vencedor; D = empate; A = time visitante vencedor) podem ser convertidos de valores textuais para inteiros, tanto para o resultado parcial (ao intervalo) quanto para o resultado final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DERROTA_MANDANTE, EMPATE, VITORIA_MANDATE = 0, 1, 2\n",
        "\n",
        "dados_pl['FTR'].replace({'A': DERROTA_MANDANTE, 'D': EMPATE, 'H': VITORIA_MANDATE}, inplace=True)\n",
        "dados_pl['HTR'].replace({'A': DERROTA_MANDANTE, 'D': EMPATE, 'H': VITORIA_MANDATE}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separação dos Conjuntos de Treinamento e de Teste\n",
        "\n",
        "A maior parte dos jogos terminou com o time mandante vencedor. Vamos armazenar as proporções de vitória e derrota dos mandantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_totais = dados_pl['FTR'].value_counts()\n",
        "\n",
        "qtd_vitorias_mandantes_total = resultados_totais[VITORIA_MANDATE]\n",
        "qtd_derrotas_mandantes_total = resultados_totais[DERROTA_MANDANTE]\n",
        "\n",
        "proporcao_vitorias_mandantes_total = qtd_vitorias_mandantes_total / sum(resultados_totais.values)\n",
        "proporcao_derrotas_mandantes_total = qtd_derrotas_mandantes_total / sum(resultados_totais.values)\n",
        "\n",
        "print('Proporção de vitórias de mandantes:', proporcao_vitorias_mandantes_total)\n",
        "print('Proporção de derrotas de mandantes:', proporcao_derrotas_mandantes_total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como as classes são desbalanceadas, vamos seguir as proporções armazenadas para dividir os conjuntos de treinamento e de teste, respeitando a distribuição das classes com uma tolerância de 1%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PERCENTUAL_TREINAMENTO = 0.8\n",
        "SEMENTE_ALEATORIA = 42\n",
        "\n",
        "np.random.seed(SEMENTE_ALEATORIA)\n",
        "\n",
        "while True:\n",
        "    dados_pl['random'] = np.random.rand(dados_pl.shape[0])\n",
        "\n",
        "    dados_treino = dados_pl[dados_pl['random'] <= PERCENTUAL_TREINAMENTO]\n",
        "    dados_teste = dados_pl[dados_pl['random'] > PERCENTUAL_TREINAMENTO]\n",
        "\n",
        "    resultados_treino = dados_treino['FTR'].value_counts()\n",
        "    \n",
        "    qtd_vitorias_mandantes_treino = resultados_treino[VITORIA_MANDATE]\n",
        "    proporcao_vitorias_mandantes_treino = qtd_vitorias_mandantes_treino / sum(resultados_treino.values)\n",
        "\n",
        "    if not (proporcao_vitorias_mandantes_total - 0.01 <= proporcao_vitorias_mandantes_treino <= proporcao_vitorias_mandantes_total + 0.01):\n",
        "        continue\n",
        "\n",
        "    qtd_derrotas_mandantes_treino = resultados_treino[DERROTA_MANDANTE]\n",
        "    proporcao_derrotas_mandantes_treino = qtd_derrotas_mandantes_treino / sum(resultados_treino.values)\n",
        "\n",
        "    if not (proporcao_derrotas_mandantes_total - 0.01 <= proporcao_derrotas_mandantes_treino <= proporcao_derrotas_mandantes_total + 0.01):\n",
        "        continue\n",
        "\n",
        "    resultados_teste = dados_teste['FTR'].value_counts()\n",
        "    \n",
        "    qtd_vitorias_mandantes_teste = resultados_teste[VITORIA_MANDATE]\n",
        "    proporcao_vitorias_mandantes_teste = qtd_vitorias_mandantes_teste / sum(resultados_teste.values)\n",
        "\n",
        "    if not (proporcao_vitorias_mandantes_total - 0.01 <= proporcao_vitorias_mandantes_teste <= proporcao_vitorias_mandantes_total + 0.01):\n",
        "        continue\n",
        "\n",
        "    qtd_derrotas_mandantes_teste = resultados_teste[DERROTA_MANDANTE]\n",
        "    proporcao_derrotas_mandantes_teste = qtd_derrotas_mandantes_teste / sum(resultados_teste.values)\n",
        "\n",
        "    if not (proporcao_derrotas_mandantes_total - 0.01 <= proporcao_derrotas_mandantes_teste <= proporcao_derrotas_mandantes_total + 0.01):\n",
        "        continue\n",
        "\n",
        "    proporcao_empates_treino = 1 - (proporcao_vitorias_mandantes_treino + proporcao_derrotas_mandantes_treino)\n",
        "    proporcao_empates_teste = 1 - (proporcao_vitorias_mandantes_teste + proporcao_derrotas_mandantes_teste)\n",
        "\n",
        "    dados_treinamento = dados_treino.drop('random', axis=1)\n",
        "    dados_teste = dados_teste.drop('random', axis=1)\n",
        "\n",
        "    break\n",
        "\n",
        "print('Shape de treinamento:', dados_treinamento.shape)\n",
        "print('Proporção de vitórias de mandantes: ', proporcao_vitorias_mandantes_treino)\n",
        "print('Proporção de empates:               ', proporcao_empates_treino)\n",
        "print('Proporção de derrotas de mandantes: ', proporcao_derrotas_mandantes_treino)\n",
        "print('\\nShape de teste:', dados_teste.shape)\n",
        "print('Proporção de vitórias de mandantes: ', proporcao_vitorias_mandantes_teste)\n",
        "print('Proporção de empates:               ', proporcao_empates_teste)\n",
        "print('Proporção de derrotas de mandantes: ', proporcao_derrotas_mandantes_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversão de Variáveis Categóricas\n",
        "\n",
        "As variáveis categóricas dos conjuntos podem ser convertidas para binárias via One Hot Encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_treinamento = pd.get_dummies(dados_treinamento)\n",
        "dados_teste = pd.get_dummies(dados_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversão dos Dados para o Formato do Numpy\n",
        "\n",
        "Como o formato do numpy facilita a manipulação das colunas para a classificação, é apropriado realizar uma conversão para tal formato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_treinamento_np = dados_treinamento.to_numpy()\n",
        "\n",
        "Y_treinamento = dados_treinamento_np[:,0]\n",
        "X_treinamento = dados_treinamento_np[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_teste_np = dados_treinamento.to_numpy()\n",
        "\n",
        "Y_teste = dados_teste_np[:,0]\n",
        "X_teste = dados_teste_np[:,1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padronização dos Dados\n",
        "\n",
        "Alguns algoritmos requerem a padronização dos dados para seu funcionamento. A padronização deve ser aplicada, separadamente (para evitar Data Leakage), aos conjuntos de treinamento e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_treinamento = StandardScaler().fit_transform(X_treinamento)\n",
        "X_teste = StandardScaler().fit_transform(X_teste)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análise Exploratória\n",
        "\n",
        "Podemos fazer uma análise exploratória com o intuito de ir examinar melhor dataset preparado, tentando identificar padrões / tendências / relacionamentos entre os atributos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlação entre os Atributos\n",
        "\n",
        "Vamos visualizar a correlação entre os atributos através da Matriz de Correlação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_treinamento = dados_treinamento.corr()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(corr_treinamento, cmap='Blues')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(corr_treinamento)), corr_treinamento.columns, rotation='vertical');\n",
        "plt.yticks(range(len(corr_treinamento)), corr_treinamento.columns);\n",
        "plt.title('Correlação entre as Variáveis', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlações Negativas\n",
        "\n",
        "Os atributos que soferam transformações via One Hot Encoding são os que estão mais não correlacionados. _Date\\_pandemic_ e _Date\\_regular_, por serem complementares, possuem correlação 0. O mesmo acontece com as correlações entre os atributos de _Home\\_Group_ e _Away\\_Group_.\n",
        "\n",
        "Ademais, os atributos de odds de vitória do time mandante e do time visitante têm uma correlação negativa visível, em virtude de serem determinadas, em maior parte, pelas probabilidades de vitória (que complementares para os eventos).\n",
        "\n",
        "Assim, dependendo dos resultados obtidos na aplicação dos algoritmos, pode ser interessante remover os atributos completamente (ou altamente) não correlacionados para fazer uma comparação de desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlações Positivas\n",
        "\n",
        "Os atributos de chutes totais (HS e AS) e chutes certos ao gol (HST, AST) apresentam correlação fortemente positiva.\n",
        "\n",
        "Já com relação ao resultado final, os atributos mais correlacionados são:\n",
        "\n",
        "- resultado ao intervalo da partida\n",
        "- quantidade de chutes certos do time mandante\n",
        "- time mandante/visitante ser pertencente ao Big Six\n",
        "\n",
        "Vamos analisá-los, separadamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Resultado ao Intervalo da Partida**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "catplot = sns.catplot(x='HTR', hue='FTR', kind='count', data=dados_treinamento, height=6, aspect=1.5, legend=False);\n",
        "catplot.set(xticklabels=['Time Mandante Perdedor', 'Empate', 'Time Mandante Vencedor'])\n",
        "\n",
        "plt.title('Comparativo de Resultados ao Meio e ao Fim das Partidas', fontdict={'size': 12, 'weight': 'bold'});\n",
        "plt.xlabel('Resultado ao Meio da Partida');\n",
        "plt.ylabel('Quantidade de Ocorrências');\n",
        "plt.legend(title='Resultado ao Fim da Partida', labels=['Time Mandante Perdedor', 'Empate', 'Time Mandante Vencedor'], loc=(1.01, 0));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos perceber que, se um dos times estiver em vantagem ao intervalo da partida, essa vantagem tende a se manter no resultado final. Já se o resultado parcial for de empate, a distribuição dos resultados finais é mais equilibrada, mas ainda com pequena propensão para se repetir o empate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Quantidade de Chutes Certos do Time Mandante**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_treinamento['HST_Range'] = pd.qcut(dados_treinamento['HST'], 5)\n",
        "\n",
        "catplot = sns.catplot(x='HST_Range', hue='FTR', kind='count', data=dados_treinamento, height=6, aspect=1.5, legend=False);\n",
        "\n",
        "plt.title('Comparativo de Chutes Certos do Mandante e Resultados das Partidas', fontdict={'size': 12, 'weight': 'bold'});\n",
        "plt.xlabel('Intervalo de Chutes Certos do Mandante ao Gol');\n",
        "plt.ylabel('Quantidade de Ocorrências');\n",
        "plt.legend(title='Resultado ao Fim da Partida', labels=['Time Mandante Perdedor', 'Empate', 'Time Mandante Vencedor'], loc=(1.01, 0));\n",
        "\n",
        "dados_treinamento.drop('HST_Range', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De maneira geral, se o time mandante tiver chutado ao menos 3 vezes diretamente para o gol, ele tendeu a sair vitorioso na partida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Pertencimento aos Times do Big 6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "is_big6_home = dados_treinamento['HomeGroup_Big6'] == 1\n",
        "is_big6_away = dados_treinamento['AwayGroup_Big6'] == 1\n",
        "is_big6_both = is_big6_home & is_big6_away\n",
        "\n",
        "dados_treinamento['Group'] = 'M. Menor x V. Menor'\n",
        "dados_treinamento.loc[is_big6_home, 'Group'] = 'M. Big6 x V. Menor'\n",
        "dados_treinamento.loc[is_big6_away, 'Group'] = 'M. Menor x V. Big6'\n",
        "dados_treinamento.loc[is_big6_both, 'Group'] = 'M. Big6 x V. Big6'\n",
        "\n",
        "catplot = sns.catplot(x='Group', hue='FTR', kind='count', data=dados_treinamento, height=6, aspect=1.5, legend=False);\n",
        "\n",
        "plt.title('Comparativo de Grupos de Mandantes x Vistantes por Grupo e Resultados das Partidas', fontdict={'size': 12, 'weight': 'bold'});\n",
        "plt.xlabel('Grupos do Confronto');\n",
        "plt.ylabel('Quantidade de Ocorrências');\n",
        "plt.legend(title='Resultado ao Fim da Partida', labels=['Time Mandante Perdedor', 'Empate', 'Time Mandante Vencedor'], loc=(1.01, 0));\n",
        "\n",
        "dados_treinamento.drop('Group', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Percebemos que os times do Big Six, quando enfrentam times \"menores\", geralmente saem com a vitória, seja jogando em casa (como mandante) ou fora (como visitante). Nos cenários de duelos entre times do mesmo grupo, o time da casa geralmente saiu vencedor na maioria dos casos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise de Componentes Principais\n",
        "\n",
        "Podemos fazer uma análise PCA para apurarmos a variabilidade dos dados. Comecemos com 2 dimensões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "componentes_principais = pca.fit_transform(X_treinamento)\n",
        "\n",
        "print('Variância por componente principal:', pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A variância somada das 2 componentes é de $\\approx$ 30%. \n",
        "\n",
        "Vamos visualizar a variação graficamente em 2 dimensões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "possiveis_resultados = {\n",
        "    DERROTA_MANDANTE: 'Derrota Mandante',\n",
        "    EMPATE: 'Empate',\n",
        "    VITORIA_MANDATE: 'Vitória Mandante'\n",
        "}\n",
        "\n",
        "dados_cps = pd.DataFrame(componentes_principais, columns=['CP1', 'CP2'])\n",
        "dados_cps['FTR'] = Y_treinamento\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for resultado in possiveis_resultados.keys():\n",
        "    indices_to_keep = dados_cps['FTR'] == resultado\n",
        "    plt.scatter(dados_cps.loc[indices_to_keep, 'CP1'], dados_cps.loc[indices_to_keep, 'CP2'], ec='black', s=50)\n",
        "    \n",
        "plt.title('Análise PCA para os Possíveis Resultados - 2 Dimensões')\n",
        "plt.xlabel('Primeira Componente Principal')\n",
        "plt.ylabel('Segunda Componente Principal')\n",
        "plt.legend(possiveis_resultados.values(), loc=(1.01, 0));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Os casos parecem bastante homogêneos. Vamos verificar o que acontece se adicionarmos mais uma dimensão ao PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=3)\n",
        "componentes_principais = pca.fit_transform(X_treinamento)\n",
        "\n",
        "print('Variância por componente principal:', pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A variância explicada aumenta um pouco, chegando próxima a 40%.\n",
        "\n",
        "O novo gráfico ainda deve mostrar certa semelhança de distribuição das classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_cps = pd.DataFrame(componentes_principais, columns=['CP1', 'CP2', 'CP3'])\n",
        "dados_cps['FTR'] = Y_treinamento\n",
        "\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "for target in possiveis_resultados.keys():\n",
        "    indices_to_keep = dados_cps['FTR'] == target\n",
        "    ax.scatter(dados_cps.loc[indices_to_keep, 'CP1'], dados_cps.loc[indices_to_keep, 'CP2'], dados_cps.loc[indices_to_keep, 'CP3'], ec='black')\n",
        "\n",
        "ax.set_xlabel('Primeira Componente Principal')\n",
        "ax.set_ylabel('Segunda Componente Principal')\n",
        "ax.set_zlabel('Terceira Componente Principal')\n",
        "ax.set_title('Análise PCA para os Possíveis Resultados - 3 Dimensões')\n",
        "plt.legend(possiveis_resultados.values());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como a variância explicada acumulada não foi tão alta para até 3 componentes, podemos expandir a análise para mais componentes principais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA()\n",
        "componentes_principais = pca.fit(X_treinamento)\n",
        "\n",
        "variancia_explicada = pca.explained_variance_\n",
        "razao_variancia_explicada = pca.explained_variance_ratio_\n",
        "razao_variancia_acumulada = np.cumsum(razao_variancia_explicada)\n",
        "\n",
        "numero_componentes = len(variancia_explicada)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(range(1,numero_componentes + 1), razao_variancia_explicada, alpha=0.8, ec='black', align='center')\n",
        "plt.title('Variância Explicada por Componente', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.xlabel('Número de Componentes', fontsize=12)\n",
        "plt.ylabel('Proporção de Variância Explicada', fontsize=12)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1,numero_componentes + 1), razao_variancia_acumulada, marker='o', linestyle='--', color='r')\n",
        "plt.title('Variância Explicada Acumulada', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.xlabel('Número de Componentes', fontsize=12)\n",
        "plt.ylabel('Proporção Acumulada de Variância Explicada', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O relativamente alto número de componentes necessário para a maior proporção de variância explicada acumulada pode indicar que a classificação em questão não será tão simples, mas ainda é possível buscar um bom resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seleção e Aplicação de Modelos\n",
        "\n",
        "Vamos começar definindo 2 funções genéricas para o ajuste e teste dos modelos. Para todos os casos, será utilizado Grid Search com Cross Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A primeira função recebe um modelo como parâmetro, realiza os ajustes e imprime os parâmetros utilizados, bem como a acurácia obtida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ajustar_modelo(modelo):\n",
        "    modelo.fit(X_treinamento, Y_treinamento)\n",
        "    print(modelo.best_params_)\n",
        "    print(f'Acurácia treinamento: {modelo.score(X_treinamento, Y_treinamento):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A segunda função recebe um modelo como parâmetro, obtém os resultados preditos pelo modelo (de acordo como o conjunto de teste), calcula as métricas de avaliação e mostra a matriz de confusão das classificações preditas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testar_modelo(modelo):\n",
        "    Y_previsto = np.array(modelo.predict(X_teste), dtype=int)\n",
        "\n",
        "    acuracia = accuracy_score(Y_teste, Y_previsto)\n",
        "    precisao = precision_score(Y_teste, Y_previsto, average='weighted')\n",
        "    recall = recall_score(Y_teste, Y_previsto, average='weighted')\n",
        "    f1 = f1_score(Y_teste, Y_previsto, average='weighted')\n",
        "\n",
        "    print(f'Acurácia teste: {acuracia:.2f}')\n",
        "    print(f'Precisão teste: {precisao:.2f}')\n",
        "    print(f'Recall teste: {recall:.2f}')\n",
        "    print(f'F1 teste: {f1:.2f}')\n",
        "\n",
        "    cm = confusion_matrix(Y_teste, Y_previsto)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='gray', cbar=True)\n",
        "    plt.title('Matriz de Confusão', fontdict={'size': 12, 'weight': 'bold'})\n",
        "    plt.xlabel('Valores Preditos', fontsize=12)\n",
        "    plt.ylabel('Valores Verdadeiros', fontsize=12)\n",
        "    plt.xticks([DERROTA_MANDANTE + 0.5, EMPATE + 0.5, VITORIA_MANDATE + 0.5], ['Derrota Mandante', 'Empate', 'Vitória Mandante'])\n",
        "    plt.yticks([DERROTA_MANDANTE + 0.5, EMPATE + 0.5, VITORIA_MANDATE + 0.5], ['Derrota Mandante', 'Empate', 'Vitória Mandante'])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K-Nearest Neighbors\n",
        "\n",
        "Para o KNN, vamos considerar como parâmetros o número de vizinhos de 1 à 49 e as distâncias euclidiana, Manhattan, Minkowski e Chebyshev."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'n_neighbors': [k for k in range(50) if k % 2 != 0],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski', 'chebyshev']   \n",
        "}\n",
        "\n",
        "modelo_knn = GridSearchCV(\n",
        "    estimator=KNeighborsClassifier(),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes\n",
        "\n",
        "Para o Naive Bayes, vamos utilizar o estimador gaussiano, com suavização testada de $1\\cdot10^{-9}$ à $1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'var_smoothing': np.logspace(0, -9, num=100),\n",
        "}\n",
        "\n",
        "modelo_bayes = GridSearchCV(\n",
        "    estimator=GaussianNB(),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_bayes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_bayes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multilayer Perceptron\n",
        "\n",
        "Para o Multilayer Perceptron, foram testadas 1 camada com 100 neurônios, ativações relu e logística com $\\alpha = 0.01$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'hidden_layer_sizes': [(100,)],\n",
        "    'activation': ['relu', 'logistic'],\n",
        "    'alpha': [0.01],\n",
        "}\n",
        "\n",
        "modelo_perceptron = GridSearchCV(\n",
        "    estimator=MLPClassifier(solver='sgd', random_state=SEMENTE_ALEATORIA, max_iter=1000),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_perceptron)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest\n",
        "\n",
        "Para o Random Forest, foram considerados estimadores de 100 à 300 (espaçados de 100 em 100), profundidade máxima de 5 à 25 (espaçadas de 5 em 5) e critérios gini e entropia para decisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'n_estimators': [i * 100 for i in range(1, 4)],\n",
        "    'max_depth': [i * 5 for i in range(1, 6)],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "}\n",
        "\n",
        "modelo_forest = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=SEMENTE_ALEATORIA),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Avaliação dos Desempenhos dos Modelos\n",
        "\n",
        "No geral, os modelos conseguiram predizer bem os cenários de partidas em que um time saiu vencedor, seja o time mandante ou o time visitante, mas tiveram dificuldade de acertar as partidas que terminaram empatadas.\n",
        "\n",
        "O resumo das métricas de avaliação obtidas nas predições para cada modelo pode ser verificado na seguinte tabela:\n",
        "\n",
        "|         Modelo        |                         Parâmetros                        | Acurácia (%) | Precisão (%) | Recall (%) | F1 (%) |\n",
        "|:---------------------:|:---------------------------------------------------------:|:------------:|:------------:|:----------:|:------:|\n",
        "|          KNN          |              Distância Manhattan, 47 Vizinhos             |      66      |      63      |     66     |   63   |\n",
        "|      Naive Bayes      |                   Distribuição Gaussiana                  |      60      |      58      |     60     |   59   |\n",
        "| Multilayer Perceptron |    Ativação Logística ($\\alpha = 0.01)$, 1 Camada com 100 neurônios    |      66      |      63      |     66     |   63   |\n",
        "|     Random Forest     | Critério Gini, Profundidade Máxima de 10 Nós, 300 Estimadores |      80      |      81      |     80     |   79   |\n",
        "\n",
        "\n",
        "O modelo que obteve as melhores métricas de avaliação e o único que conseguiu acertar a maior parte dos empates foi o Random Forest. Podemos verificar as importâncias de cada atributo através do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nomes_atributos = dados_treinamento.columns[1:]\n",
        "importacias_atributos = modelo_forest.best_estimator_.feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(nomes_atributos, importacias_atributos, color='darkcyan', ec='black')\n",
        "plt.title('Importâncias dos Atributos Segundo o Random Forest', fontdict={'size': 12, 'weight': 'bold'})\n",
        "plt.xlabel('Nomes dos Atributos', fontsize=12)\n",
        "plt.ylabel('Importâncias', fontsize=12)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O resultado ao meio da partida (HTR) foi o atributo mais predominante para o modelo, seguido dos atributos de chutes certos ao gol (HST e AST). A pouca influência dos atributos de casas de apostas (AvgH, AvgD, e AvgA) pode ser explicada pela substituição manual da maioria das odds na preparação dos dados, que, por ter sido feita de maneira bastante genérica, pode ter acarretado em uma perda de influência do atributo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Re-Preparação dos Dados\n",
        "\n",
        "Vamos reaplicar os algoritmos utilizando agora os atributos de maior importância e desconsiderando as colunas convertidas com One Hot Encoding e a Odd de vitória do time visitante (complementar às outras odds).\n",
        "\n",
        "### Seleção dos Atributos de Interesse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas_interesse = [\n",
        "    'HomeGroup_Big6', 'AwayGroup_Big6', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'AvgH', 'AvgD', 'HTR', 'FTR'\n",
        "]\n",
        "\n",
        "colunas_nao_interesse = [nome_coluna for nome_coluna in dados_treinamento.columns if nome_coluna not in colunas_interesse]\n",
        "\n",
        "dados_treinamento.drop(columns=colunas_nao_interesse, inplace=True)\n",
        "dados_teste.drop(columns=colunas_nao_interesse, inplace=True)\n",
        "\n",
        "print('Shape dos datasets novos:')\n",
        "print(dados_treinamento.shape)\n",
        "print(dados_teste.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversão dos Dados para o Formato do Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_treinamento_np = dados_treinamento.to_numpy()\n",
        "\n",
        "Y_treinamento = dados_treinamento_np[:,0]\n",
        "X_treinamento = dados_treinamento_np[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_teste_np = dados_treinamento.to_numpy()\n",
        "\n",
        "Y_teste = dados_teste_np[:,0]\n",
        "X_teste = dados_teste_np[:,1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Re-Seleção e Re-Aplicação de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K-Nearest Neighbors\n",
        "\n",
        "Para o KNN, vamos continuar considerando como parâmetros o número de vizinhos de 1 à 49 e as distâncias euclidiana, Manhattan, Minkowski e Chebyshev."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'n_neighbors': [k for k in range(50) if k % 2 != 0],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski', 'chebyshev']   \n",
        "}\n",
        "\n",
        "modelo_knn = GridSearchCV(\n",
        "    estimator=KNeighborsClassifier(),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes\n",
        "\n",
        "Para o Naive Bayes, vamos prosseguir novamente com o estimador gaussiano, com suavização testada de $1\\cdot10^{-9}$ à $1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'var_smoothing': np.logspace(0, -9, num=100),\n",
        "}\n",
        "\n",
        "modelo_bayes = GridSearchCV(\n",
        "    estimator=GaussianNB(),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_bayes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_bayes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multilayer Perceptron\n",
        "\n",
        "Para o Multilayer Perceptron, foram testadas, novamente, 1 camada com 100 neurônios, ativações relu e logística com $\\alpha = 0.01$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'hidden_layer_sizes': [(100,)],\n",
        "    'activation': ['relu', 'logistic'],\n",
        "    'alpha': [0.01],\n",
        "}\n",
        "\n",
        "modelo_perceptron = GridSearchCV(\n",
        "    estimator=MLPClassifier(solver='sgd', random_state=SEMENTE_ALEATORIA, max_iter=1000),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_perceptron)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest\n",
        "\n",
        "Para o Random Forest, vamos continuar considerando estimadores de 100 à 300 (espaçados de 100 em 100), profundidade máxima de 5 à 25 (espaçadas de 5 em 5) e critérios gini e entropia para decisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parametros_grid = {\n",
        "    'n_estimators': [i * 100 for i in range(1, 4)],\n",
        "    'max_depth': [i * 5 for i in range(1, 6)],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "}\n",
        "\n",
        "modelo_forest = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=SEMENTE_ALEATORIA),\n",
        "    param_grid=parametros_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy',\n",
        "    return_train_score=False,\n",
        "    verbose=True,\n",
        "    error_score='raise',\n",
        "    n_jobs=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ajustar_modelo(modelo_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testar_modelo(modelo_forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Avaliação dos Desempenhos dos Novos Modelos\n",
        "\n",
        "A nova aplicação dos algoritmos levou a uma piora nas métricas de acerto no KNN, a uma melhora no Naive Bayes e leve melhora no Random Forest. As métricas de acerto do Multilayer Perceptron permaneceram bastante semelhantes. Vale destacar que o percentual de acertos em cenários de empates, que já era relativamente bom no Random Forest, melhorou um pouco mais, mas permaneceu baixo nos outros modelos.\n",
        "\n",
        "As métricas de avaliação obtidas nas predições para cada novo modelo podem ser sumarizadas na seguinte tabela:\n",
        "\n",
        "|         Modelo        |                         Parâmetros                        | Acurácia (%) | Precisão (%) | Recall (%) | F1 (%) |\n",
        "|:---------------------:|:---------------------------------------------------------:|:------------:|:------------:|:----------:|:------:|\n",
        "|          KNN          |              Distância Euclideana, 43 Vizinhos             |      63      |      60      |     63     |   58   |\n",
        "|      Naive Bayes      |                   Distribuição Gaussiana                  |      62      |      60      |     62     |   61   |\n",
        "| Multilayer Perceptron |    Ativação Logística ($\\alpha = 0.01)$, 100 Camadas    |      66      |      63      |     66     |   62   |\n",
        "|     Random Forest     | Critério Gini, Profundidade Máxima de 10, 300 Estimadores |      81      |      81      |     81     |   80   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aplicação nos Últimos Jogos\n",
        "\n",
        "Vamos utilizar o modelo do classificador Random Forest para fazer predições nas 10 partidas da rodada ocorrida no último fim de semana (de 2 à 3 de dezembro de 2023). As partidas ocorridas foram:\n",
        "\n",
        "|               Jogo               | Placar Final |\n",
        "|:--------------------------------:|:------------:|\n",
        "| Arsenal vs Wolves | 2 x 1 |\n",
        "| Brentford vs Luton | 3 x 1 |\n",
        "| Burnley vs Sheffield United | 5 x 0 |\n",
        "| Nott'm Forest vs Everton | 0 x 1 |\n",
        "| Newcastle vs Manchester United | 1 x 0 |\n",
        "| Burnemouth vs Aston Villa | 2 x 2 |\n",
        "| Chelsea vs Brighton | 3 x 2 |\n",
        "| Liverpool vs Fulham | 4 x 3 |\n",
        "| West Ham vs Crystal Palace | 1 x 1 |\n",
        "| Manchester City vs Tottenham | 3 x 3 |\n",
        "\n",
        "Os dados relativos à cada partida foram manualmente colocados no arquivo \"ultimos-jogos.csv\", já em um formato pronto para serem processados pelo modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_ultimos_jogos = pd.read_csv('./data/ultimos-jogos.csv')\n",
        "dados_ultimos_jogos_np = dados_ultimos_jogos.to_numpy()\n",
        "\n",
        "X_ultimos_jogos = dados_ultimos_jogos_np[:,1:]\n",
        "Y_ultimos_jogos = np.array(dados_ultimos_jogos_np[:,0], dtype=int)\n",
        "\n",
        "Y_previsto = np.array(modelo_forest.predict(X_ultimos_jogos), dtype=int)\n",
        "dados_ultimos_jogos.insert(1, 'PR', Y_previsto)\n",
        "\n",
        "acuracia = accuracy_score(Y_ultimos_jogos, Y_previsto)\n",
        "\n",
        "display(dados_ultimos_jogos)\n",
        "print('Acurácia:', acuracia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O modelo previu corretamente o resultado de 6 partidas:\n",
        "\n",
        "- Arsenal vs Wolves\n",
        "- Brentford vs Luton\n",
        "- Burnley vs Sheffield United\n",
        "- Burnemouth vs Aston Villa\n",
        "- Chelsea vs Brighton\n",
        "- Liverpool vs Fulham\n",
        "\n",
        "E errou outras 4 partidas:\n",
        "\n",
        "- Nott'm Forest vs Everton (previu empate)\n",
        "- Newcastle vs Manchester United (previu empate)\n",
        "- West Ham vs Crystal Palace (previu visitante)\n",
        "- Manchester City vs Tottenham (previu visitante)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusão\n",
        "\n",
        "Ao longo deste projeto, foram explorados dados estatísticos de partidas da Premier League, utilizando diferentes modelos de aprendizado de máquina para tentar prever os resultados finais dos jogos. Os modelos avaliados foram KNN, Naive Bayes, Multilayer Perceptron e Random Forest. Apesar de a aplicação da Análise de Componentes Principais (PCA) ter sugerido certa complexidade na classificação, indicando a presença de variáveis intercorrelacionadas, o modelo Random Forest destacou-se, alcançando bons resultados em comparação com os demais. \n",
        "\n",
        "O resultado ao meio da partida se mostrou como o atributo que exerceu mais influência nas classificações, seguido de chutes (certos e totais) ao gol, escanteios, faltas cometidas e pertencimento dos grupos ao Big Six.\n",
        "\n",
        "Uma observação interessante foi a dificuldade dos modelos em prever empates, sendo o Random Forest o mais eficaz nesse cenário. Exemplificando essa dificuldade, a seção \"Aplicação nos Últimos Jogos\" mostrou que, dentre as partidas erradas, 2 tiveram empates previstos incorretamente e as outras 2 tiveram um vencedor previsto incorretamente, enquanto o resultado ocorrido na prática foi de empate.\n",
        "\n",
        "Sobre possíveis melhorias, é evidente a limitação na abordagem adotada para substituição de valores para as probabilidades faltantes de casas de apostas. Uma estratégia mais robusta poderia envolver uma substituição mais fundamentada, considerando resultados históricos e ajustando as probabilidades de vitória para os times do Big 6 também em partidas fora de casa."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
