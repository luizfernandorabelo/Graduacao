{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respostas Questionário IV\n",
    "\n",
    "**Aluno:** Luiz Fernando Rabelo (11796893)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "Para a resolução do questionário, foram utilizadas as bibliotecas _numpy_, _pandas_, _matplotlib_, _seaborn_, e _sklearn_, as quais são importadas abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos Dados de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo a ser tomado é a leitura dos dados de treinamento e teste, os quais contam com os seguintes atributos:\n",
    "\n",
    "- _PassengerId:_ número de identificação do passageiro\n",
    "- _Survived:_ sobrevivência do passageiro (0 = não | 1 = sim)\n",
    "- _Pclass:_ classe da passagem (1 = primeira, 2 = segunda ou 3 = terceira)\n",
    "- _Name:_ nome do passageiro\n",
    "- _Sex:_ sexo do passageiro\n",
    "- _Age:_ idade do passageiro (em anos)\n",
    "- _Sibsp:_ número de irmãos/cônjuges à bordo\n",
    "- _Parch:_ número de pais/filhos à bordo\n",
    "- _Ticket:_ número do bilhete\n",
    "- _Fare:_ valor do bilhete\n",
    "- _Cabin:_ número da cabine\n",
    "- _Embarked:_ porto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento = pd.read_csv('./train.csv')\n",
    "dados_teste = pd.read_csv('./test.csv')\n",
    "\n",
    "print('Shape treinamento:', dados_treinamento.shape)\n",
    "print('Shape teste:', dados_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É perceptível que os dados de teste possuem 1 coluna à menos que os dados de treinamento. Essa coluna é justamente a _Survived_ a ser predita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza, Conversão e Padronização dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de Atributos Irrelevantes\n",
    "\n",
    "Alguns atributos não possuem influência na sobrevivência dos passageiros, como _PassengerId_, _Name_ e _Ticket_. Tais atributos podem ser removidos dos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_teste = dados_teste['PassengerId']\n",
    "\n",
    "dados_treinamento.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "dados_teste.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Valores Nulos\n",
    "\n",
    "A fim de melhorar a integridade dos dados lidos, é necessário verificar a melhor maneira de se tratar valores nulos nos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que o atributo _Cabin_ é o que possui mais registros com valores nulos (em ambos os datasets). Por se tratar de um atributo complementar, sem tanta influência projetada, é possível descartar a coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento.drop(['Cabin'], axis=1, inplace=True)\n",
    "dados_teste.drop(['Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já os atributos _Age_, _Embarked_ e _Fare_ parecem ser mais determinantes para a classificação e a análise deve ser um pouco mais cautelosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para _Age_, os valores nulos podem ser preenchidos com a média dos não nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento['Age'].fillna(dados_treinamento['Age'].mean(), inplace=True)\n",
    "dados_teste['Age'].fillna(dados_teste['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para _Embarked_, como se tratam de apenas 2 registros, os valores nulos podem ser substituídos para o porto mais provável (S = Southampton)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento['Embarked'].hist(figsize=(4,4));\n",
    "dados_treinamento['Embarked'].fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para _Fare_, o único valor nulo pode ser preenchdo com a mediana dos não nulos, uma medida não sensível à outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste['Fare'].fillna(dados_teste['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de Atributos Nominais\n",
    "\n",
    "Os atributos nominais dos datasets podem ser convertidos para numéricos via one-hot-encoding, já implementado pelo _pandas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento_com_nominais = dados_treinamento\n",
    "\n",
    "dados_treinamento = pd.get_dummies(dados_treinamento)\n",
    "dados_teste = pd.get_dummies(dados_teste)\n",
    "\n",
    "dados_treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação dos Dados para Classificação\n",
    "\n",
    "Os dados de treinamento e de teste podem ser convertidos para matrizes do _numpy_, de forma a facilitar o processamento na classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento_np = dados_treinamento.to_numpy()\n",
    "\n",
    "Y_treinamento = dados_treinamento_np[:,0]   # linhas da coluna survived\n",
    "X_treinamento = dados_treinamento_np[:,1:]  # linhas das demais colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste_np = dados_teste.to_numpy()\n",
    "\n",
    "X_teste = dados_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento = StandardScaler().fit_transform(X_treinamento)\n",
    "X_teste = StandardScaler().fit_transform(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Descritiva dos Dados\n",
    "\n",
    "É possível plotar uma Matriz de Correlação entre os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_treinamento = dados_treinamento.corr()\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(corr_treinamento, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr_treinamento)), corr_treinamento.columns, rotation='vertical');\n",
    "plt.yticks(range(len(corr_treinamento)), corr_treinamento.columns);\n",
    "plt.title('Correlação entre as Variáveis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela Matriz de Correlação atributo _Survived_ está mais positivamente relacionado com _Sex\\_female_, _Fare_ e _Embarked\\_C_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Sex', hue='Survived', kind='count', data=dados_treinamento_com_nominais);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enquanto cerca de 75% das mulheres sobreviveram, apenas cerca de 20% tiveram a vida preservada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento_com_nominais['Fare_Range'] = pd.qcut(dados_treinamento_com_nominais['Fare'], 4)\n",
    "\n",
    "sns.barplot(x='Fare_Range', y='Survived', data=dados_treinamento_com_nominais);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto maior o preço do bilhete, maior o percentual de sobreviventes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Embarked', hue='Survived', kind='count', data=dados_treinamento_com_nominais);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais da metade dos passageiros que embarcaram em Cherbourg sobreviveram, quase metade dos que embarcaram em Queenstown sobreviveram e a menor parte (cerca de 1/3) dos que embarcaram em Southampton sobreviveram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda pela Matriz de Correlação, o atributo _Survived_ está mais negativamente relacionado com _Sex\\_male_ (atributo complementar ao _Sex\\_female_ já apresentado), _Pclass_, _Embarked\\_S_ (atributo complementar ao _Embarked\\_C_ já apresentado) e _Age_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dados_treinamento_com_nominais.groupby(['Pclass', 'Survived']).size().unstack(), annot=True, fmt='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria dos passageiros que embarcaram na primeira classe sobreviveu. Na segunda classe, a distribuição foi equilibrada. Já para a terceira classe, a maioria (75%) dos passageiros não sobreviveu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='Sex', y='Age', hue='Survived', data=dados_treinamento_com_nominais, split=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior parte das crianças masculinas sobreviveu, mas as crianças femininas não conseguiram a sobrevivência em sua maioria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "componentes_principais = pca.fit(X_treinamento)\n",
    "\n",
    "variancia_explicada = pca.explained_variance_\n",
    "razao_variancia_explicada = pca.explained_variance_ratio_\n",
    "razao_variancia_acumulada = np.cumsum(razao_variancia_explicada)\n",
    "\n",
    "numero_componentes = len(variancia_explicada)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1,numero_componentes + 1), razao_variancia_explicada, alpha=0.8, ec='black', align='center')\n",
    "plt.title('Variância Explicada por Componente', fontdict={'size': 12, 'weight': 'bold'})\n",
    "plt.xlabel('Número de Componentes', fontsize=12)\n",
    "plt.ylabel('Proporção de Variância Explicada', fontsize=12)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1,numero_componentes + 1), razao_variancia_acumulada, marker='o', linestyle='--', color='r')\n",
    "plt.title('Variância Explicada Acumulada', fontdict={'size': 12, 'weight': 'bold'})\n",
    "plt.xlabel('Número de Componentes', fontsize=12)\n",
    "plt.ylabel('Proporção Acumulada de Variância Explicada', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Modelos e Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = {\n",
    "    'n_neighbors': [k for k in range(50) if k % 2 != 0],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski', 'chebyshev']   \n",
    "}\n",
    "\n",
    "modelo = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=parametros_grid,\n",
    "    cv=10,\n",
    "    scoring='roc_auc',\n",
    "    return_train_score=False,\n",
    "    verbose=True,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "modelo.fit(X_treinamento, Y_treinamento)\n",
    "print(modelo.best_params_)\n",
    "modelo.score(X_treinamento, Y_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_previsto = np.array(modelo.predict(X_teste), dtype=int)\n",
    "\n",
    "dados_previsao = pd.DataFrame()\n",
    "dados_previsao['PassengerId'] = ids_teste\n",
    "dados_previsao['Survived'] = Y_previsto\n",
    "\n",
    "dados_previsao.to_csv('prediction-knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submetendo no Kaggle, foi obtido um score de **0.75358**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = {\n",
    "    'n_estimators': [i * 100 for i in range(1, 4)],\n",
    "    'max_depth': [i * 5 for i in range(1, 6)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "modelo = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=parametros_grid,\n",
    "    cv=10,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "modelo.fit(X_treinamento, Y_treinamento)\n",
    "print(modelo.best_params_)\n",
    "modelo.score(X_treinamento, Y_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_previsto = np.array(modelo.predict(X_teste), dtype=int)\n",
    "\n",
    "dados_previsao = pd.DataFrame()\n",
    "dados_previsao['PassengerId'] = ids_teste\n",
    "dados_previsao['Survived'] = Y_previsto\n",
    "\n",
    "dados_previsao.to_csv('prediction-random-forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submetendo no Kaggle, foi obtido um score de **0.79186**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "}\n",
    "\n",
    "modelo = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=parametros_grid,\n",
    "    cv=10,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "modelo.fit(X_treinamento, Y_treinamento)\n",
    "print(modelo.best_params_)\n",
    "modelo.score(X_treinamento, Y_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_previsto = np.array(modelo.predict(X_teste), dtype=int)\n",
    "\n",
    "dados_previsao = pd.DataFrame()\n",
    "dados_previsao['PassengerId'] = ids_teste\n",
    "dados_previsao['Survived'] = Y_previsto\n",
    "\n",
    "dados_previsao.to_csv('prediction-logistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submetendo no Kaggle, foi obtido um score de **0.77511**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50,50), (30,30,30), (10,20,30), (30,20,10)],\n",
    "    'activation': ['relu', 'logistic', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "}\n",
    "\n",
    "modelo = GridSearchCV(\n",
    "    estimator=MLPClassifier(max_iter=1000),\n",
    "    param_grid=parametros_grid,\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "modelo.fit(X_treinamento, Y_treinamento)\n",
    "print(modelo.best_params_)\n",
    "modelo.score(X_treinamento, Y_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_previsto = np.array(modelo.predict(X_teste), dtype=int)\n",
    "\n",
    "dados_previsao = pd.DataFrame()\n",
    "dados_previsao['PassengerId'] = ids_teste\n",
    "dados_previsao['Survived'] = Y_previsto\n",
    "\n",
    "dados_previsao.to_csv('prediction-perceptron.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submetendo no Kaggle, foi obtido um score de **0.76315**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentários Finais\n",
    "\n",
    "Em resumo, os scores obtidos por cada modelo no conjunto de teste foram:\n",
    "\n",
    "| Classificador | Parâmetros | Score | \n",
    "|:-------------:|:-----:|:----------:|\n",
    "| KNN | Distância Manhattan, 13 Vizinhos | 75,35% | \n",
    "| Random Forest | Critério Gini, 5 de Profundidade Máxima, 100 Estimadores | 79,18% | \n",
    "| Regressão Logística | C 0.01, Solver lbfgs | 77,51% |\n",
    "| Multilayer Perceptron | Ativação Relu, $\\alpha$ 0.001, Camadas (100), Taxa de Aprendizado Constante  | 76,31% |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
