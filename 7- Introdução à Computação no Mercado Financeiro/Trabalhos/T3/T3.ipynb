{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trabalho 3 - Uso de Técnicas de ML Aplicadas em Trading Sistemático\n",
        "\n",
        "**Aluno:** Luiz Fernando Rabelo (11796893)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bibliotecas Utilizadas\n",
        "\n",
        "Para a resolução do trabalho, foram utilizadas as bibliotecas numpy, ta (Technical Analysis), yfinance (Yahoo Finance) e sklearn, as quais são importadas abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.volume import MFIIndicator\n",
        "from ta.trend import MACD\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ativos Considerados\n",
        "\n",
        "A fim de compor uma lista de ações a serem testadas, foi priorizada a diversificação do setor de atuação das empresas. Nesse sentido, considerando um período de análise variando de 1 de janeiro de 2003 à 31 de dezembro de 2022, foram escolhidas as seguintes ações:\n",
        "\n",
        "- MGLU3 (Magazine Luiza);\n",
        "- VALE3 (Vale);\n",
        "- OIBR3 (Oi);\n",
        "- BBAS3 (Banco do Brasil);\n",
        "- POMO4 (Marcopolo).\n",
        "\n",
        "Nota: nem todas as ações possuem dados registrados no período supracitado. Nesses casos, foi obtido um histórico de um período máximo das ações."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicialização de lista de ações e dicionário de dados:\n",
        "acoes_consideradas = ['MGLU3.SA', 'VALE3.SA', 'OIBR3.SA', 'BBAS3.SA', 'POMO4.SA']\n",
        "dados_acoes = {acao: {} for acao in acoes_consideradas}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição do intervalo de consulta:\n",
        "data_inicio = '2003-01-01'\n",
        "data_fim = '2022-12-31'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armazenamento dos dados históricos:\n",
        "for acao in acoes_consideradas:\n",
        "    historico = yf.download(acao, data_inicio, data_fim, '1d')\n",
        "    dados_acoes[acao] = historico[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
        "    # Adequação dos dados ao fechamento ajustado:\n",
        "    for index, row in dados_acoes[acao].iterrows():\n",
        "        dados_acoes[acao].at[index, 'High'] = row['High'] / row['Close'] * row['Adj Close']\n",
        "        dados_acoes[acao].at[index, 'Low'] = row['Low'] / row['Close'] * row['Adj Close']\n",
        "        dados_acoes[acao].at[index, 'Close'] = row['Adj Close']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estratégias de Aprendizado\n",
        "\n",
        "As ações foram analisadas, individualmente, para definir uma tática de trading sistemático com base na classificação de algoritmos de aprendizado de máquina. Esses algoritmos levaram em consideração diferentes indicadores de entrada:\n",
        "\n",
        "- Relative Strength Index (momentum);\n",
        "- Money Flow Index (volume);\n",
        "- Moving Average Convergence Divergence (tendência).\n",
        "\n",
        "Para definir uma referência a ser seguida, foram estabelecidas janelas de 11 dias, sobre as quais foram calculados os pontos de mínimo (compra ideal) e de máximo (venda ideal) da ação.\n",
        "\n",
        "A missão dos algoritmos de ML conduziu-se na tentativa de combinar informações desses indicadores de forma a tomar decisões de compra e venda de uma ação. Durante o período de análise, foram realizados vários treinamentos (em partições de 400 dias, sendo 120 dias para treinamento e 280 para teste).\n",
        "\n",
        "Os valores dos indicadores foram convertidos para a mesma ordem de grandeza a fim de simplificar o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def obtem_parametros_entrada(dados):\n",
        "    # Relative Strength Index:\n",
        "    ind_rsi = RSIIndicator(close=dados['Close'], window=24, fillna=True)\n",
        "    dados['rsi_r'] = ind_rsi.rsi() / 100.0\n",
        "\n",
        "    # Money Flow Index:\n",
        "    ind_mfi = MFIIndicator(high=dados['High'], low=dados['Low'], close=dados['Close'], volume=dados['Volume'], window=24, fillna=True)\n",
        "    dados['mfi_r'] = ind_mfi.money_flow_index() / 100.0\n",
        "\n",
        "    # Moving Average Convergence Divergence:\n",
        "    ind_macd = MACD(close=dados['Close'], window_slow=24, window_fast=12, fillna=True)\n",
        "    dados['macd'] = ind_macd.macd()\n",
        "\n",
        "    return dados[['rsi_r', 'mfi_r', 'macd']].reset_index().drop(['Date'], axis=1).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição de valores das decisões:\n",
        "COMPRA, MANTEM, VENDE = 1, 0, -1\n",
        "\n",
        "def obtem_parametros_saida(dados):\n",
        "    # Criação da coluna \"Action\" para decisões:\n",
        "    dados['Action'] = MANTEM\n",
        "\n",
        "    # Inicialização de variáveis auxiliares:\n",
        "    periodo_inicio = 0\n",
        "    tamanho_janela = 11 \n",
        "    periodo_fim = periodo_inicio + tamanho_janela\n",
        "    total_dados = dados.shape[0]\n",
        "\n",
        "    # Definição dos pontos de compra e venda ideais:\n",
        "    while periodo_fim < total_dados:\n",
        "        minimo = dados['Close'].iloc[periodo_inicio:periodo_fim].min()\n",
        "        maximo = dados['Close'].iloc[periodo_inicio:periodo_fim].max()\n",
        "        for i in range(periodo_inicio, periodo_fim + 1):\n",
        "            if dados['Close'].iloc[i] == minimo:\n",
        "                dados.loc[dados.index[i], 'Action'] = MANTEM\n",
        "                dados.loc[dados.index[i+1], 'Action'] = COMPRA\n",
        "            elif dados['Close'].iloc[i] == maximo:\n",
        "                dados.loc[dados.index[i], 'Action'] = MANTEM\n",
        "                dados.loc[dados.index[i+1], 'Action'] = VENDE\n",
        "        periodo_inicio = periodo_fim + 1\n",
        "        periodo_fim = periodo_inicio + tamanho_janela\n",
        "    \n",
        "    return dados['Action'].reset_index().drop(['Date'], axis=1).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def realiza_treinamento(dados_entrada, dados_saida, clf, dataframe):\n",
        "    # Definição do tamanho de cada partição:\n",
        "    tamanho_particao = 400\n",
        "\n",
        "    # Definição da quantidade de dados para treino por partição:\n",
        "    qtd_treino = 120\n",
        "\n",
        "    # Cálculo da quantidade de partições (treinos e testes):\n",
        "    total_particoes = dados_entrada.shape[0] // tamanho_particao\n",
        "\n",
        "    # Criação da coluna \"ML-Action\":\n",
        "    dataframe['ML-Action'] = MANTEM\n",
        "\n",
        "    # Criação do vetor que conterá as ações finais:\n",
        "    acoes_finais = []\n",
        "\n",
        "    # Inicialização de variáveis auxiliares para exibição de acurácia:\n",
        "    soma_acuracia_treino = soma_acuracia_teste = 0\n",
        "\n",
        "    # Treino e teste por partição:\n",
        "    for p in range(total_particoes):\n",
        "        i = p * tamanho_particao  # índice de início da partição\n",
        "\n",
        "        # Definição dos dados de treino:\n",
        "        dados_entrada_treino = dados_entrada[i:i+qtd_treino]\n",
        "        dados_saida_treino = dados_saida[i+1:i+qtd_treino+1]\n",
        "\n",
        "        # Definição dos dados de teste:\n",
        "        dados_entrada_teste = dados_entrada[i+qtd_treino:i+tamanho_particao]\n",
        "        dados_saida_teste = dados_saida[i+qtd_treino+1:i+tamanho_particao+1]\n",
        "\n",
        "        # Treino do modelo:\n",
        "        clf.fit(dados_entrada_treino, dados_saida_treino.ravel());\n",
        "\n",
        "        # Avaliação dos resultados do conjunto de dados de treinamento:\n",
        "        dados_preditos_treino = clf.predict(dados_entrada_treino)\n",
        "        soma_acuracia_treino += metrics.accuracy_score(dados_saida_treino, dados_preditos_treino)\n",
        "\n",
        "        # Avaliação dos resultados do conjunto de dados de teste:\n",
        "        dados_preditos_teste = clf.predict(dados_entrada_teste)\n",
        "        soma_acuracia_teste += metrics.accuracy_score(dados_saida_teste, dados_preditos_teste)\n",
        "\n",
        "        # Contabilização das decisões:\n",
        "        acoes_finais = np.append(acoes_finais, dados_preditos_treino)\n",
        "        acoes_finais = np.append(acoes_finais, dados_preditos_teste) \n",
        "    \n",
        "    # Exibição da média das acurácias em treinos e testes para todas as partições:\n",
        "    print('Acurácia Média Treino:', round(soma_acuracia_treino / total_particoes, 2))\n",
        "    print('Acurácia Média Teste:', round(soma_acuracia_teste / total_particoes, 2))\n",
        "    \n",
        "    # Adição das decisões ao dataframe:\n",
        "    acoes_finais = np.append(acoes_finais, [MANTEM] * (dataframe.shape[0] % tamanho_particao))\n",
        "    dataframe['ML-Action'] = acoes_finais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avalia_resultado_trade(dados, investimento_inicial, nome_ativo, nome_algoritmo):\n",
        "    # Criação da coluna \"Saldo\":\n",
        "    dados['Saldo'] = 0\n",
        "\n",
        "    # Inicialização de variáveis auxiliares:\n",
        "    saldo = investimento_inicial\n",
        "    operacao = MANTEM\n",
        "    total_trades = total_positivos = 0\n",
        "    media_positivos = media_negativos = 0\n",
        "\n",
        "    # Registro do valor do saldo:\n",
        "    for i in range(dados.shape[0]):\n",
        "        if dados['ML-Action'].iloc[i] == COMPRA and operacao == MANTEM:\n",
        "            valor_negociado = dados['Close'].iloc[i]\n",
        "            operacao = COMPRA\n",
        "        elif dados['ML-Action'].iloc[i] == COMPRA and operacao == VENDE:\n",
        "            retorno_trade = valor_negociado / dados['Close'].iloc[i] - 1\n",
        "            if retorno_trade > 0:\n",
        "                total_positivos += 1\n",
        "                media_positivos += retorno_trade\n",
        "            else:\n",
        "                media_negativos += retorno_trade\n",
        "            saldo *= (1 + retorno_trade)\n",
        "            total_trades += 1\n",
        "            operacao = MANTEM\n",
        "        elif dados['ML-Action'].iloc[i] == VENDE and operacao == MANTEM:\n",
        "            valor_negociado = dados['Close'].iloc[i]\n",
        "            operacao = VENDE\n",
        "        elif dados['ML-Action'].iloc[i] == VENDE and operacao == COMPRA:\n",
        "            retorno_trade = dados['Close'].iloc[i] / valor_negociado - 1\n",
        "            if retorno_trade > 0:\n",
        "                total_positivos += 1\n",
        "                media_positivos += retorno_trade\n",
        "            else:\n",
        "                media_negativos += retorno_trade\n",
        "            saldo *= (1 + retorno_trade)\n",
        "            total_trades += 1\n",
        "            operacao = MANTEM\n",
        "        dados.loc[dados.index[i], 'Saldo'] = saldo\n",
        "\n",
        "    # Impressão de informações sobre as operações realizadas:\n",
        "    if total_positivos > 0:\n",
        "        print(f'Trades totais: {total_trades}, Trades positivos: {total_positivos} ({round(total_positivos / total_trades * 100, 2)}%)')\n",
        "        print(f'Retorno médio trades positivos: {round(media_positivos / total_positivos * 100, 2)}%, Retorno médio trades negativos: {round(media_negativos / (total_trades - total_positivos) * 100, 2) if total_positivos != total_trades else 0}%')\n",
        "        print(f'Rentabilidade buy and hold: {round((dados[\"Close\"].iloc[-1] / dados[\"Close\"].iloc[0] - 1) * 100, 2)}%, Rentabilidade ML trade: {round((dados[\"Saldo\"].iloc[-1] / dados[\"Saldo\"].iloc[0] - 1) * 100, 2)}%')\n",
        "    else:\n",
        "        print('Não foram feitos trades no período')\n",
        "    \n",
        "    # Plot da Curva de Capital:\n",
        "    dados[['Close', 'Saldo']] = dados[['Close', 'Saldo']] / dados[['Close', 'Saldo']].iloc[0] * 100\n",
        "    dados[['Close', 'Saldo']].iloc[0:].plot(figsize = (15,5), title=f'Curva de Capital {nome_ativo} - {nome_algoritmo}');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análises por Ativo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Magazine Luiza - MGLU3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados = dados_acoes['MGLU3.SA'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtenção dos Dados de Entrada e Saída"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_entrada = obtem_parametros_entrada(dados)\n",
        "dados_saida = obtem_parametros_saida(dados)\n",
        "\n",
        "print(dados_entrada.shape, dados_saida.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15, ), max_iter=1000000, random_state=1, activation='tanh')\n",
        "realiza_treinamento(dados_entrada, dados_saida, mlp, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'MGLU3', 'Multilayer Perceptron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=1, max_depth=7, n_estimators=5)\n",
        "realiza_treinamento(dados_entrada, dados_saida, rf, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'MGLU3', 'Random Forest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vale - VALE3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados = dados_acoes['VALE3.SA'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtenção dos Dados de Entrada e Saída"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_entrada = obtem_parametros_entrada(dados)\n",
        "dados_saida = obtem_parametros_saida(dados)\n",
        "\n",
        "print(dados_entrada.shape, dados_saida.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15, ), max_iter=1000000, random_state=1, activation='tanh')\n",
        "realiza_treinamento(dados_entrada, dados_saida, mlp, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'VALE3', 'Multilayer Perceptron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=1, max_depth=7, n_estimators=5)\n",
        "realiza_treinamento(dados_entrada, dados_saida, rf, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'VALE3', 'Random Forest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Oi - OIBR3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados = dados_acoes['OIBR3.SA'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtenção dos Dados de Entrada e Saída"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_entrada = obtem_parametros_entrada(dados)\n",
        "dados_saida = obtem_parametros_saida(dados)\n",
        "\n",
        "print(dados_entrada.shape, dados_saida.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15, ), max_iter=1000000, random_state=1, activation='tanh')\n",
        "realiza_treinamento(dados_entrada, dados_saida, mlp, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'OIBR3', 'Multilayer Perceptron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=1, max_depth=7, n_estimators=5)\n",
        "realiza_treinamento(dados_entrada, dados_saida, rf, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'OIBR3', 'Random Forest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Banco do Brasil - BBAS3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados = dados_acoes['BBAS3.SA'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtenção dos Dados de Entrada e Saída"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_entrada = obtem_parametros_entrada(dados)\n",
        "dados_saida = obtem_parametros_saida(dados)\n",
        "\n",
        "print(dados_entrada.shape, dados_saida.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15, ), max_iter=1000000, random_state=1, activation='tanh')\n",
        "realiza_treinamento(dados_entrada, dados_saida, mlp, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'BBAS3', 'Multilayer Perceptron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=1, max_depth=7, n_estimators=5)\n",
        "realiza_treinamento(dados_entrada, dados_saida, rf, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'BBASE', 'Random Forest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Marco Polo - POMO4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados = dados_acoes['POMO4.SA'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtenção dos Dados de Entrada e Saída"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_entrada = obtem_parametros_entrada(dados)\n",
        "dados_saida = obtem_parametros_saida(dados)\n",
        "\n",
        "print(dados_entrada.shape, dados_saida.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15, ), max_iter=1000000, random_state=1, activation='tanh')\n",
        "realiza_treinamento(dados_entrada, dados_saida, mlp, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'POMO4', 'Multilayer Perceptron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificador Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=1, max_depth=7, n_estimators=5)\n",
        "realiza_treinamento(dados_entrada, dados_saida, rf, dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avalia_resultado_trade(dados, 100, 'POMO4', 'Random Forest')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
